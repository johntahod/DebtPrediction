{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a- Read the data file “Hearts_s.csv” (from github using the following command), and assign it to a Pandas DataFrame:\n",
    "df = pd.read_csv(\"https://github.com/mpourhoma/CS4661/raw/master/Heart_s.csv\")\n",
    "\n",
    "b- Check out the dataset. As you see, the dataset contains a number of features including both contextual and biological factors (e.g. age, gender, vital signs, ...). The last column “AHD” is the label with “Yes” meaning that a human subject has Heart Disease, and “No” meaning that the subject does not have Heart Disease.\n",
    "\n",
    "c- As you see, there are at least 3 categorical features in the dataset (Gender, ChestPain, Thal). Let’s ignore these categorical features for now, only keep the numerical features and build your feature matrix and label vector.\n",
    "\n",
    "\n",
    "\n",
    "d- Split the dataset into testing and training sets with the following parameters: test_size=0.25, random_state=6.\n",
    "\n",
    "e- Use KNN (with k=3), Decision Tree (with random_state=5), and Logistic Regression Classifiers to predict Heart Disease based on the training/testing datasets that you built in part (d). Then check, compare, and report the accuracy of these 3 classifiers. Which one is the best? Which one is the worst?\n",
    "\n",
    "f- Now, we want to use the categorical features as well! To this end, we have to perform a feature engineering process called OneHotEncoding for the categorical features. To do this, each categorical feature should be replaced with dummy columns in the feature table (one column for each possible value of a categorical feature), and then encode it in a binary manner such that only one of the dummy columns can take “1” at a time (and zero for the rest). For example, “Gender” can take two values “m” and “f”. Thus, we need to replace this feature (in the feature table) by 2 columns titled “m” and “f”. Wherever we have a male subject, we can put “1” and ”0” in the columns “m” and “f”. Wherever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#part a \n",
    "df = pd.read_csv(\"https://github.com/mpourhoma/CS4661/raw/master/Heart_s.csv\")\n",
    "# print(df)\n",
    "\n",
    "#part b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part c \n",
    "feature_cols = ['Age','RestBP','Chol','RestECG','MaxHR','Oldpeak']\n",
    "\n",
    "label_cols = ['AHD']\n",
    "\n",
    "\n",
    "\n",
    "X = df[feature_cols]\n",
    "X.head()\n",
    "\n",
    "y = df[label_cols]\n",
    "y[::10]\n",
    "\n",
    "\n",
    "#part d\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
    "                                                    random_state=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN k = 3 :  0.6447368421052632\n",
      "logistic regression :  0.6710526315789473\n",
      "decision tree  0.618421052631579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#part e \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "#Use KNN (with k=3)\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"KNN k = 3 : \",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "#Decision Tree (with random_state=5\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "my_decisiontree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "my_logreg = LogisticRegression()\n",
    "\n",
    "# We can use the method \"fit\" of the objects \"my_logreg\" and \"my_decisiontree\" along with training dataset and labels to train the model.\n",
    "\n",
    "my_logreg.fit(X_train, y_train)\n",
    "\n",
    "my_decisiontree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_predict_lr = my_logreg.predict(X_test)\n",
    "\n",
    "y_predict_dt = my_decisiontree.predict(X_test)\n",
    "\n",
    "\n",
    "score_lr = accuracy_score(y_test, y_predict_lr)\n",
    "score_dt = accuracy_score(y_test, y_predict_dt)\n",
    "\n",
    "print(\"logistic regression : \",score_lr)\n",
    "print(\"decision tree \",score_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Categorical boolean mask\n",
    "categorical_feature_mask = X.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "\n",
    "\n",
    "categorical_cols = X.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "\n",
    "# # apply le on categorical feature columns\n",
    "# X[categorical_cols] = X[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "# X[categorical_cols].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
